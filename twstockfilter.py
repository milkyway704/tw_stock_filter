import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime
import urllib3

# [cite_start]ç¦ç”¨ SSL å®‰å…¨è­¦å‘Š [cite: 1]
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(page_title="å°è‚¡ RS ç¯©é¸å™¨", page_icon="ğŸ“ˆ")

# --- 1. è‚¡ç¥¨åœ°åœ– (SSL å¿½ç•¥ç‰ˆ) ---
@st.cache_data(ttl=604800)
def get_stock_mapping():
    urls = {
        "TWSE": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2",
        "TPEX": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"
    }
    mapping = {}
    headers = {'User-Agent': 'Mozilla/5.0'}
    for market, url in urls.items():
        try:
            # [cite_start]é—œéµï¼šverify=False è§£æ±ºé›²ç«¯ SSL å ±éŒ¯ [cite: 1]
            resp = requests.get(url, headers=headers, timeout=10, verify=False)
            resp.encoding = 'ms950'
            soup = BeautifulSoup(resp.text, 'html.parser')
            rows = soup.find_all('tr')
            prefix = "TWSE" if market == "TWSE" else "TPEX"
            for row in rows:
                cols = row.find_all('td')
                if not cols: continue
                text = cols[0].get_text(strip=True).replace('\u3000', ' ')
                parts = text.split(' ')
                if len(parts) >= 2 and parts[0].isdigit():
                    mapping[str(parts[0])] = {"name": parts[1], "prefix": prefix}
        except:
            continue
    return mapping

# --- 2. MoneyDJ æŠ“å– ---
def fetch_moneydj_rs(weeks, min_rank):
    url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
    try:
        resp = requests.get(url, timeout=15, verify=False)
        resp.encoding = 'big5'
        match = re.search(r"parent\.sStklistAll\s*=\s*'([^']+)'", resp.text)
        if match:
            raw_codes = match.group(1).encode('utf-8').decode('unicode-escape')
            return [c.strip() for c in raw_codes.split(',') if c.strip().isdigit()]
    except:
        pass
    return []

# --- 3. ä»‹é¢ä½ˆå±€ ---
st.title("ğŸ‡¹ğŸ‡¼ å°è‚¡ RS Rank ç¯©é¸å™¨")

# è¨­å®šå€
weeks = st.slider("é¸æ“‡é€±æ•¸", 1, 52, 1)
min_rank = st.number_input("RS Rank å¤§æ–¼ç­‰æ–¼", 1, 99, 80)
max_count = st.number_input("è‡³å¤šé¡¯ç¤ºå¹¾ç­†", 1, 500, 200)

# é‡æ–°æ”¾å› MoneyDJ é€£çµ (æœƒéš¨åƒæ•¸è®Šå‹•)
mdj_url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
st.markdown(f"ğŸ” [ğŸ”— é–‹å•Ÿ MoneyDJ åŸå§‹ç¶²é ç¢ºèª]({mdj_url})")

btn = st.button("ğŸš€ åŸ·è¡Œç¯©é¸", type="primary", use_container_width=True)

st.divider()

if btn:
    with st.spinner('æ­£åœ¨åŒæ­¥æ•¸æ“š...'):
        mapping = get_stock_mapping()
        codes = fetch_moneydj_rs(weeks, min_rank)
        
        if codes:
            final_codes = codes[:max_count]
            tv_list = []
            display_data = []
            
            for c in final_codes:
                info = mapping.get(str(c))
                mkt = info['prefix'] if info else "TWSE"
                name = info['name'] if info else "åç¨±å¾…æŸ¥"
                tv_list.append(f"{mkt}:{c}")
                display_data.append({"ä»£è™Ÿ": c, "åç¨±": name, "å¸‚å ´": mkt})
            
            st.success(f"æ‰¾åˆ°å…± {len(codes)} æª”è‚¡ç¥¨")
            
            # TradingView å€å¡Š
            current_date = datetime.now().strftime("%Y_%m_%d")
            csv_string = ",".join(tv_list)
            st.subheader("ğŸ”¥ TradingView åŒ¯å…¥å­—ä¸²")
            st.code(csv_string)
            
            st.download_button(
                label=f"ğŸ“¥ ä¸‹è¼‰ TW_{current_date}.txt",
                data=csv_string,
                file_name=f"TW_{current_date}.txt",
                mime="text/plain",
                use_container_width=True
            )
            
            st.subheader("ğŸ“‹ è©³ç´°æ¸…å–®")
            st.dataframe(display_data, use_container_width=True)
        else:
            st.warning("æŸ¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹è‚¡ç¥¨ã€‚")
            st.info(f"å»ºè­°é»æ“Šä¸Šæ–¹é€£çµè‡³ MoneyDJ ç¶²é ç¢ºèªæ˜¯å¦æœ‰è³‡æ–™ã€‚")