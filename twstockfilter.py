import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
from datetime import datetime, timedelta
import urllib3

# ç¦ç”¨ SSL å®‰å…¨è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¨­å®šé é¢
st.set_page_config(page_title="RS Rank Filter", page_icon="ğŸ“ˆ", layout="centered")

# --- é€šç”¨å·¥å…· ---
def get_tw_time():
    return datetime.utcnow() + timedelta(hours=8)

# --- 1. å°è‚¡å°ˆç”¨ï¼šè‚¡ç¥¨åœ°åœ– ---
@st.cache_data(ttl=604800)
def get_stock_mapping():
    urls = {
        "TWSE": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2",
        "TPEX": "https://isin.twse.com.tw/isin/C_public.jsp?strMode=4"
    }
    mapping = {}
    headers = {'User-Agent': 'Mozilla/5.0'}
    for market, url in urls.items():
        try:
            resp = requests.get(url, headers=headers, timeout=10, verify=False)
            resp.encoding = 'ms950'
            soup = BeautifulSoup(resp.text, 'html.parser')
            rows = soup.find_all('tr')
            prefix = "TWSE" if market == "TWSE" else "TPEX"
            for row in rows:
                cols = row.find_all('td')
                if not cols: continue
                text = cols[0].get_text(strip=True).replace('\u3000', ' ')
                parts = text.split(' ')
                if len(parts) >= 2 and parts[0].isdigit():
                    mapping[str(parts[0])] = {"name": parts[1], "prefix": prefix}
        except: continue
    return mapping

# --- 2. å°è‚¡å°ˆç”¨ï¼šMoneyDJ æŠ“å– ---
def fetch_moneydj_rs(weeks, min_rank):
    url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
    try:
        resp = requests.get(url, timeout=15, verify=False)
        resp.encoding = 'big5'
        match = re.search(r"parent\.sStklistAll\s*=\s*'([^']+)'", resp.text)
        if match:
            raw_codes = match.group(1).encode('utf-8').decode('unicode-escape')
            return [c.strip() for c in raw_codes.split(',') if c.strip().isdigit()]
    except: pass
    return []

# --- 3. ç¾è‚¡å°ˆç”¨ï¼šGoogle Sheet æŠ“å– ---
@st.cache_data(ttl=3600)
def fetch_us_rs_from_gsheet():
    gsheet_url = "https://docs.google.com/spreadsheets/d/18EWLoHkh2aiJIKQsJnjOjPo63QFxkUE2U_K8ffHCn1E/edit?usp=sharing"
    csv_url = gsheet_url.replace('/edit?usp=sharing', '/export?format=csv')
    try:
        df = pd.read_csv(csv_url)
        return df
    except Exception as e:
        st.error(f"ç¾è‚¡æ•¸æ“šè®€å–å¤±æ•—: {e}")
        return None

# --- UI ä»‹é¢é–‹å§‹ ---
# 1. æ¨™é¡Œå±…ä¸­
st.markdown("<h1 style='text-align: center;'>RS Rank Filter</h1>", unsafe_allow_html=True)

# 2. Tabs åˆ‡æ› (US / TW)
tab_us, tab_tw = st.tabs(["ğŸ‡ºğŸ‡¸ US (ç¾è‚¡)", "ğŸ‡¹ğŸ‡¼ TW (å°è‚¡)"])

# --- ç¾è‚¡åˆ†é  ---
with tab_us:
    st.subheader("ç¾è‚¡ RS ç¯©é¸")
    st.caption("è‡ªå‹•å°ä½ï¼šé¿é–‹ç¶²å€èªªæ˜åˆ—ï¼Œç²¾ç¢ºæŠ“å– Symbol èˆ‡ RS Rnk")
    min_rs_us = st.number_input("RS Rank æœ€ä½æ¨™", 1, 100, 90, key="us_input")
    
    if st.button("ğŸš€ åŸ·è¡Œç¾è‚¡ç¯©é¸", type="primary", use_container_width=True):
        with st.spinner('æ­£åœ¨åˆ†æè¡¨æ ¼çµæ§‹...'):
            gsheet_url = "https://docs.google.com/spreadsheets/d/18EWLoHkh2aiJIKQsJnjOjPo63QFxkUE2U_K8ffHCn1E/edit?usp=sharing"
            csv_url = gsheet_url.replace('/edit?usp=sharing', '/export?format=csv')
            
            try:
                # 1. è®€å–æ•¸æ“š (header=None ç¢ºä¿ä¸æ¼æ‰ä»»ä½•ä¸€åˆ—)
                df_raw = pd.read_csv(csv_url, header=None)
                
                symbol_idx = None
                rs_idx = None
                data_start_row = 0
                
                # 2. æƒæå‰ 10 åˆ—å°‹æ‰¾çœŸæ­£çš„æ¨™é¡Œè¡Œ
                for row_i in range(min(10, len(df_raw))):
                    row_list = df_raw.iloc[row_i].astype(str).tolist()
                    # åªè¦é€™ä¸€è¡Œæœ‰ Symbol ä¸”æœ‰ RS Rnk 
                    if 'Symbol' in row_list and any('RS Rnk' in str(x) for x in row_list):
                        symbol_idx = row_list.index('Symbol')
                        # å°‹æ‰¾åŒ…å« 'RS Rnk' çš„æ¬„ä½ç´¢å¼•
                        for col_i, col_val in enumerate(row_list):
                            if 'RS Rnk' in str(col_val):
                                rs_idx = col_i
                        data_start_row = row_i + 1 # è³‡æ–™å¾æ¨™é¡Œçš„ä¸‹ä¸€åˆ—é–‹å§‹
                        break
                
                if symbol_idx is not None and rs_idx is not None:
                    # 3. æå–æ•¸æ“š
                    df_final = df_raw.iloc[data_start_row:, [symbol_idx, rs_idx]].copy()
                    df_final.columns = ['Symbol', 'RS_Rank']
                    
                    # è½‰æ›æ•¸å€¼ä¸¦æ¸…ç†
                    df_final['RS_Rank'] = pd.to_numeric(df_final['RS_Rank'], errors='coerce')
                    df_final = df_final.dropna(subset=['Symbol', 'RS_Rank'])
                    
                    # 4. ç¯©é¸èˆ‡æ’åº
                    filtered_us = df_final[df_final['RS_Rank'] >= min_rs_us].sort_values(by='RS_Rank', ascending=False)
                    
                    if not filtered_us.empty:
                        # 5. äº¤æ˜“æ‰€å‰ç¶´åˆ¤æ–·é‚è¼¯ (TradingView æ ¼å¼)
                        def add_tv_prefix(s):
                            s = str(s).strip().upper()
                            # ç°¡å–®åˆ¤æ–·ï¼š4ç¢¼(å«)ä»¥ä¸Š NASDAQï¼Œ3ç¢¼(å«)ä»¥ä¸‹ NYSE
                            # é€™æ˜¯ç¾è‚¡æœ€å¸¸è¦‹çš„åˆ†é¡æ–¹å¼ï¼Œèƒ½åŒ¹é… 95% ä»¥ä¸Šè‚¡ç¥¨
                            return f"NASDAQ:{s}" if len(s) >= 4 else f"NYSE:{s}"
                        
                        tv_symbols = [add_tv_prefix(s) for s in filtered_us['Symbol']]
                        csv_string_us = ",".join(tv_symbols)
                        
                        st.success(f"è§£ææˆåŠŸï¼æ‰¾åˆ° {len(filtered_us)} æª”è‚¡ç¥¨")
                        st.subheader("ğŸ”¥ TradingView åŒ¯å…¥å­—ä¸²")
                        st.code(csv_string_us)
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰åŒ¯å…¥æª” (.txt)",
                            data=csv_string_us,
                            file_name=f"US_RS{min_rs_us}_{get_tw_time().strftime('%Y%m%d')}.txt",
                            use_container_width=True
                        )
                        st.dataframe(filtered_us, use_container_width=True)
                    else:
                        st.warning(f"ç›®å‰æ¸…å–®ä¸­æ²’æœ‰ RS Rank >= {min_rs_us} çš„è‚¡ç¥¨ã€‚")
                else:
                    st.error("ç„¡æ³•åœ¨è¡¨æ ¼ä¸­å®šä½ 'Symbol' æˆ– 'RS Rnk' æ¬„ä½ã€‚")
                    st.info(f"åµæ¸¬åˆ°çš„ç¬¬ä¸€åˆ—å…§å®¹ï¼š{df_raw.iloc[0].tolist()[:5]}...")
                    
            except Exception as e:
                st.error(f"åŸ·è¡Œå‡ºéŒ¯: {e}")
                
# --- å°è‚¡åˆ†é  ---
with tab_tw:
    st.subheader("å°è‚¡ RS ç¯©é¸")
    
    # ä¿®æ”¹è™•ï¼šé€±æ•¸æ”¹ç‚º number_input (é è¨­ 2)ï¼Œä¸¦èˆ‡æ’åä¸‹é™ä½µæ’
    col1, col2 = st.columns(2)
    with col1:
        weeks = st.number_input("é€±æ•¸", 1, 52, 2) 
    with col2:
        min_rank = st.number_input("RS Rank ä¸‹é™", 1, 99, 80)
    
    max_count = st.slider("é¡¯ç¤ºä¸Šé™", 50, 500, 200)

    # ä¿ç•™ MoneyDJ åŸå§‹ç¶²é é€£çµ
    mdj_url = f"https://moneydj.emega.com.tw/z/zk/zkf/zkResult.asp?D=1&A=x@250,a@{weeks},b@{min_rank}&site="
    st.markdown(f"ğŸ” [ğŸ”— é–‹å•Ÿ MoneyDJ åŸå§‹ç¶²é ç¢ºèª]({mdj_url})")

    if st.button("ğŸš€ åŸ·è¡Œå°è‚¡ç¯©é¸", type="primary", use_container_width=True):
        with st.spinner('åŒæ­¥æ•¸æ“šä¸­...'):
            mapping = get_stock_mapping()
            codes = fetch_moneydj_rs(weeks, min_rank)
            
            if codes:
                final_codes = codes[:max_count]
                tv_list_tw = []
                display_tw = []
                
                for c in final_codes:
                    info = mapping.get(str(c))
                    mkt = info['prefix'] if info else "TWSE"
                    name = info['name'] if info else f"ä»£è™Ÿ {c}"
                    tv_list_tw.append(f"{mkt}:{c}")
                    display_tw.append({"ä»£è™Ÿ": c, "åç¨±": name, "å¸‚å ´": mkt})
                
                st.success(f"æ‰¾åˆ° {len(codes)} æª”æ¨™çš„")
                csv_tw = ",".join(tv_list_tw)
                st.code(csv_tw)
                st.download_button("ğŸ“¥ ä¸‹è¼‰ TW æ¸…å–®", csv_tw, f"TW_{get_tw_time().strftime('%Y_%m_%d')}.txt", use_container_width=True)
                st.dataframe(display_tw, use_container_width=True)
            else:
                st.warning("æŸ¥ç„¡ç¬¦åˆæ¢ä»¶ä¹‹è‚¡ç¥¨ã€‚")